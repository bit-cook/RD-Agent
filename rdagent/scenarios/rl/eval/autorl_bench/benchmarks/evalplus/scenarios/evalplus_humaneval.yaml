model_path: openai_compat://my-model
data_path: evalplus://humaneval
baseline: baselines/humanevalplus.json
metric: pass@1

benchmark: evalplus
docker_image: autorl-bench/eval-evalplus:0.1

model:
  provider: openai_compat
  base_url: http://host.docker.internal:8000/v1
  api_key: EMPTY
  temperature: 0.0
  max_tokens: 1024

params:
  dataset: humaneval
  mode: two_stage
  greedy: true
  timeout_sec: 3
  n_samples: 1

stages:
  - entry: "python /app/env_entry.py eval --scenario /scenario.yaml --output /output --stage codegen"
    network: host
  - entry: "python /app/env_entry.py eval --scenario /scenario.yaml --output /output --stage evaluate"
    network: none
    read_only: true
    cap_drop_all: true
    pids_limit: 256
