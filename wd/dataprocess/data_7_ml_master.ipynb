{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bb513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import math\n",
    "# import json\n",
    "# import os\n",
    "# from typing import Dict, List\n",
    "# import json\n",
    "# from collections import defaultdict\n",
    "# from itertools import combinations\n",
    "# import os\n",
    "\n",
    "# # ====== 固定处理这个 path ======\n",
    "# BASE_PATH = Path(\n",
    "#     \"/data/userdata/v-lijingyuan/JobAndExp/amlt_project/logs_allowed-parrot/20260108-005156_aerial-cactus-identification\"\n",
    "# )\n",
    "\n",
    "# records = []\n",
    "\n",
    "\n",
    "# def collect_metric_steps(step, step_to_data, visited=None):\n",
    "#     if visited is None:\n",
    "#         visited = set()\n",
    "\n",
    "#     if step in visited:\n",
    "#         return []\n",
    "\n",
    "#     visited.add(step)\n",
    "\n",
    "#     data = step_to_data.get(step)\n",
    "#     if data is None:\n",
    "#         return []\n",
    "\n",
    "#     results = []\n",
    "\n",
    "#     for p in data.get(\"parents\", []):\n",
    "#         results.extend(collect_metric_steps(p, step_to_data, visited))\n",
    "\n",
    "#         parent_data = step_to_data.get(p)\n",
    "#         if parent_data is not None and parent_data.get(\"metric\") is not None:\n",
    "#             results.append(p)\n",
    "\n",
    "#     return results\n",
    "\n",
    "\n",
    "# def build_parent_plan_chain(step, step_to_data):\n",
    "#     steps = collect_metric_steps(step, step_to_data)\n",
    "\n",
    "#     self_data = step_to_data.get(step)\n",
    "#     if self_data is not None and self_data.get(\"metric\") is not None:\n",
    "#         steps.append(step)\n",
    "\n",
    "#     if not steps:\n",
    "#         return \"ROOT\"\n",
    "\n",
    "#     steps = sorted(set(steps))\n",
    "\n",
    "#     return \" -> \".join(\n",
    "#         step_to_data[s].get(\"plan\", \"\") for s in steps\n",
    "#     )\n",
    "\n",
    "\n",
    "# def find_nearest_parent_metric(step, step_to_data, visited=None):\n",
    "#     \"\"\"\n",
    "#     找最近的一个有 metric 的 parent\n",
    "#     \"\"\"\n",
    "#     if visited is None:\n",
    "#         visited = set()\n",
    "#     if step in visited:\n",
    "#         return None\n",
    "\n",
    "#     visited.add(step)\n",
    "\n",
    "#     data = step_to_data.get(step)\n",
    "#     if data is None:\n",
    "#         return None\n",
    "\n",
    "#     for p in data.get(\"parents\", []):\n",
    "#         parent_data = step_to_data.get(p)\n",
    "#         if parent_data is None:\n",
    "#             continue\n",
    "\n",
    "#         if parent_data.get(\"metric\") is not None:\n",
    "#             return parent_data.get(\"metric\")\n",
    "\n",
    "#         hit = find_nearest_parent_metric(p, step_to_data, visited)\n",
    "#         if hit is not None:\n",
    "#             return hit\n",
    "\n",
    "#     return None\n",
    "\n",
    "\n",
    "\n",
    "# for journal_path in BASE_PATH.rglob(\"json/JOURNAL.jsonl\"):\n",
    "#     competition = BASE_PATH.name.split(\"_\", 1)[-1]\n",
    "#     experiment = \"allowed-parrot\"\n",
    "\n",
    "#     # ---------- Phase 1 ----------\n",
    "#     step_to_data = {}\n",
    "#     rows = []\n",
    "\n",
    "#     with open(journal_path) as f:\n",
    "#         for line in f:\n",
    "#             if not line.strip():\n",
    "#                 continue\n",
    "#             obj = json.loads(line)\n",
    "#             data = obj[\"data\"]\n",
    "#             rows.append(data)\n",
    "\n",
    "#             step = data.get(\"step\")\n",
    "#             if step is not None:\n",
    "#                 step_to_data[step] = data\n",
    "\n",
    "#     # ---------- Phase 2 ----------\n",
    "#     for data in rows:\n",
    "#         self_metric = data.get(\"metric\")\n",
    "#         parent_metric = find_nearest_parent_metric(\n",
    "#             data.get(\"step\"),\n",
    "#             step_to_data\n",
    "#         )\n",
    "\n",
    "#         if self_metric is not None and parent_metric is not None:\n",
    "#             score_diff = self_metric - parent_metric\n",
    "#         else:\n",
    "#             score_diff = float(\"nan\")\n",
    "\n",
    "#         records.append({\n",
    "#             \"competition\": competition,\n",
    "#             \"experiment\": experiment,\n",
    "#             \"plan\": data.get(\"plan\"),\n",
    "#             \"metric\": self_metric,\n",
    "#             \"metric_maximize\": data.get(\"metric_maximize\"),\n",
    "#             \"hypothesis_chain\": build_parent_plan_chain(\n",
    "#                 data.get(\"step\"),\n",
    "#                 step_to_data\n",
    "#             ),\n",
    "#             \"score diff\": score_diff,\n",
    "#         })\n",
    "\n",
    "# df = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99948ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# json_records = []\n",
    "\n",
    "# # 只保留有 score diff 的\n",
    "# df_valid = df[df[\"score diff\"].notna()].copy()\n",
    "\n",
    "# for (competition, experiment), g in df_valid.groupby([\"competition\", \"experiment\"]):\n",
    "#     items = g.to_dict(\"records\")\n",
    "#     if len(items) < 2:\n",
    "#         continue\n",
    "\n",
    "#     # 是否越大越好\n",
    "#     bigger_is_better = bool(items[0][\"metric_maximize\"])\n",
    "\n",
    "#     # 统一方向：maximize -> +1, minimize -> -1\n",
    "#     direction = 1 if bigger_is_better else -1\n",
    "\n",
    "#     for a, b in combinations(items, 2):\n",
    "#         score_a = direction * a[\"score diff\"]\n",
    "#         score_b = direction * b[\"score diff\"]\n",
    "\n",
    "#         # 判定 winner / loser\n",
    "#         if score_a == score_b:\n",
    "#             continue  # 可选：完全一样就跳过\n",
    "\n",
    "#         winner, loser = (a, b) if score_a > score_b else (b, a)\n",
    "\n",
    "#         # pair 的相对优势强度（始终 >= 0）\n",
    "#         pair_score_diff = abs(winner[\"score diff\"] - loser[\"score diff\"])\n",
    "\n",
    "#         json_records.append({\n",
    "#             \"competition\": competition,\n",
    "#             \"winner\": winner[\"hypothesis_chain\"],\n",
    "#             \"loser\": loser[\"hypothesis_chain\"],\n",
    "#             \"score_diff\": pair_score_diff,\n",
    "#         })\n",
    "\n",
    "# # 写 JSON\n",
    "# with open(\"hypothesis_pairs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(json_records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# print(f\"Total json records: {len(json_records)}\")\n",
    "# print(json_records[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dad13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "    #\"/data/userdata/v-lijingyuan/JobAndExp/amlt_project/logs_social-crawdad\"\n",
    "    #\"/data/userdata/v-lijingyuan/JobAndExp/logs_useful-egret\"\n",
    "# ====== 所有 competition 的父目录 ======\n",
    "ROOT_PATH = Path(\n",
    "    #\"/data/userdata/v-lijingyuan/JobAndExp/logs_useful-egret\"\n",
    "    #\"/data/userdata/v-lijingyuan/JobAndExp/logs_relaxing-cowbird\"\n",
    "    \"/data/userdata/v-lijingyuan/JobAndExp/amlt_project/logs_cute-mammoth\"\n",
    "    #\"/data/userdata/v-lijingyuan/JobAndExp/amlt_project/logs_relaxing-cowbird\"\n",
    ")\n",
    "\n",
    "json_records = []\n",
    "\n",
    "\n",
    "def collect_metric_steps(step, step_to_data, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if step in visited:\n",
    "        return []\n",
    "    visited.add(step)\n",
    "\n",
    "    data = step_to_data.get(step)\n",
    "    if data is None:\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for p in data.get(\"parents\", []):\n",
    "        results.extend(collect_metric_steps(p, step_to_data, visited))\n",
    "        parent_data = step_to_data.get(p)\n",
    "        if parent_data is not None and parent_data.get(\"metric\") is not None:\n",
    "            results.append(p)\n",
    "    return results\n",
    "\n",
    "\n",
    "def build_parent_plan_chain(step, step_to_data):\n",
    "    steps = collect_metric_steps(step, step_to_data)\n",
    "\n",
    "    self_data = step_to_data.get(step)\n",
    "    if self_data is not None and self_data.get(\"metric\") is not None:\n",
    "        steps.append(step)\n",
    "\n",
    "    if not steps:\n",
    "        return \"ROOT\"\n",
    "\n",
    "    steps = sorted(set(steps))\n",
    "    return \"->\".join(step_to_data[s].get(\"plan\", \"\") for s in steps)\n",
    "\n",
    "\n",
    "def find_nearest_parent_metric(step, step_to_data, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if step in visited:\n",
    "        return None\n",
    "    visited.add(step)\n",
    "\n",
    "    data = step_to_data.get(step)\n",
    "    if data is None:\n",
    "        return None\n",
    "\n",
    "    for p in data.get(\"parents\", []):\n",
    "        parent_data = step_to_data.get(p)\n",
    "        if parent_data is None:\n",
    "            continue\n",
    "        if parent_data.get(\"metric\") is not None:\n",
    "            return parent_data.get(\"metric\")\n",
    "        hit = find_nearest_parent_metric(p, step_to_data, visited)\n",
    "        if hit is not None:\n",
    "            return hit\n",
    "    return None\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 遍历：competition → experiment → JOURNAL.jsonl\n",
    "# ============================================================\n",
    "for competition_dir in ROOT_PATH.iterdir():\n",
    "    if not competition_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    # competition 名\n",
    "    competition = competition_dir.name.split(\"_\", 1)[-1]\n",
    "\n",
    "    for journal_path in competition_dir.rglob(\"json/JOURNAL.jsonl\"):\n",
    "        experiment = competition_dir.name.split(\"_\", 1)[0].replace(\"logs_\", \"\")\n",
    "        # ---------- Phase 1 ----------\n",
    "        step_to_data = {}\n",
    "        rows = []\n",
    "\n",
    "        with open(journal_path) as f:\n",
    "            for line in f:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                obj = json.loads(line)\n",
    "                data = obj[\"data\"]\n",
    "                rows.append(data)\n",
    "                step = data.get(\"step\")\n",
    "                if step is not None:\n",
    "                    step_to_data[step] = data\n",
    "\n",
    "        # ---------- Phase 2：构造 df ----------\n",
    "        records = []\n",
    "        for data in rows:\n",
    "            #print(data)\n",
    "            self_metric = data.get(\"metric\")\n",
    "            parent_metric = find_nearest_parent_metric(\n",
    "                data.get(\"step\"), step_to_data\n",
    "            )\n",
    "            #print(self_metric,parent_metric)\n",
    "            \n",
    "            if self_metric is not None and parent_metric is not None:\n",
    "                score_diff = self_metric - parent_metric\n",
    "            else:\n",
    "                score_diff = float(\"nan\")\n",
    "\n",
    "            records.append({\n",
    "                \"competition\": competition,\n",
    "                \"experiment\": experiment,\n",
    "                \"metric_maximize\": data.get(\"metric_maximize\"),\n",
    "                \"hypothesis_chain\": build_parent_plan_chain(\n",
    "                    data.get(\"step\"), step_to_data\n",
    "                ),\n",
    "                \"score_diff\": score_diff,\n",
    "            })\n",
    "        #print(len(records))\n",
    "        df = pd.DataFrame(records)\n",
    "        df_valid = df[df[\"score_diff\"].notna()]\n",
    "        #print(len(df_valid))\n",
    "        if len(df_valid) < 2:\n",
    "            continue\n",
    "        #print(df_valid)\n",
    "        # ---------- Phase 3：pairwise preference ----------\n",
    "        items = df_valid.to_dict(\"records\")\n",
    "        bigger_is_better = bool(items[0][\"metric_maximize\"])\n",
    "        direction = 1 if bigger_is_better else -1\n",
    "\n",
    "        for a, b in combinations(items, 2):\n",
    "            score_a = direction * a[\"score_diff\"]\n",
    "            score_b = direction * b[\"score_diff\"]\n",
    "\n",
    "            if score_a == score_b:\n",
    "                continue\n",
    "\n",
    "            winner, loser = (a, b) if score_a > score_b else (b, a)\n",
    "            pair_score_diff = abs(winner[\"score_diff\"] - loser[\"score_diff\"])\n",
    "            #print(competition)\n",
    "            json_records.append({\n",
    "                \"competition\": competition,\n",
    "                \"winner\": winner[\"hypothesis_chain\"],\n",
    "                \"loser\": loser[\"hypothesis_chain\"],\n",
    "                \"score_diff\": pair_score_diff,\n",
    "            })\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 输出 JSON\n",
    "# ===============================\n",
    "with open(\"/data/userdata/v-lijingyuan/vail_data/aira1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Total preference pairs: {len(json_records)}\")\n",
    "#print(json_records[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "h1_path = \"/data/userdata/v-lijingyuan/vail_data/h1.json\"\n",
    "h2_path = \"/data/userdata/v-lijingyuan/vail_data/h2.json\"\n",
    "h3_path = \"/data/userdata/v-lijingyuan/vail_data/h3.json\"\n",
    "\n",
    "output_path = \"/data/userdata/v-lijingyuan/vail_data/valid.json\"\n",
    "\n",
    "# 读取 H1 和 H2\n",
    "with open(h1_path, \"r\") as f:\n",
    "    h1_data = json.load(f)\n",
    "\n",
    "with open(h2_path, \"r\") as f:\n",
    "    h2_data = json.load(f)\n",
    "with open(h3_path, \"r\") as f:\n",
    "    h3_data = json.load(f)\n",
    "# 简单合并两个列表\n",
    "combined = h1_data + h2_data+h3_data\n",
    "\n",
    "# # 保存\n",
    "# with open(output_path, \"w\") as f:\n",
    "#     json.dump(combined, f, indent=2)\n",
    "\n",
    "# print(f\"Combined JSON saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3299a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pairs_from_journal(path: str):\n",
    "    \"\"\"\n",
    "    从单个 journal.json 构造 preference pairs\n",
    "    \"\"\"\n",
    "    # -------- 1. extract competition name --------\n",
    "    base = os.path.basename(os.path.dirname(os.path.dirname(path)))\n",
    "    # e.g. text-normalization-challenge-english-language_xxxxx\n",
    "    comp_name = base.split(\"_\")[0]\n",
    "\n",
    "    # -------- 2. load data --------\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    nodes = data[\"nodes\"]\n",
    "    node2parent = data.get(\"node2parent\", {})\n",
    "    node_dict = {n[\"id\"]: n for n in nodes}\n",
    "\n",
    "    # -------- 3. helpers --------\n",
    "    def get_score(node):\n",
    "        if node is None:\n",
    "            return 0.0\n",
    "        val = node.get(\"metric\", {}).get(\"value\")\n",
    "        return 0.0 if val is None else float(val)\n",
    "\n",
    "    def get_reward(node, parent_node):\n",
    "        metric = node.get(\"metric\", {})\n",
    "        maximize = metric.get(\"maximize\")\n",
    "\n",
    "        cur_score = get_score(node)\n",
    "        parent_score = get_score(parent_node)\n",
    "\n",
    "        if maximize is True:\n",
    "            return cur_score - parent_score\n",
    "        elif maximize is False:\n",
    "            return parent_score - cur_score\n",
    "        else:\n",
    "            # maximize is None\n",
    "            return 0.0\n",
    "\n",
    "    def build_plan_chain_from_root(node_id: str) -> str:\n",
    "        chain = []\n",
    "        cur = node_id\n",
    "        while cur is not None:\n",
    "            plan = node_dict[cur].get(\"plan\")\n",
    "            if plan is not None:\n",
    "                chain.append(plan)\n",
    "            cur = node2parent.get(cur)\n",
    "        return \" -> \".join(reversed(chain))\n",
    "\n",
    "    # -------- 4. build node-level results --------\n",
    "    results = []\n",
    "\n",
    "    for node in nodes:\n",
    "        node_id = node[\"id\"]\n",
    "        parent_id = node2parent.get(node_id)\n",
    "        parent_node = node_dict[parent_id] if parent_id is not None else None\n",
    "\n",
    "        cur_score = get_score(node)\n",
    "        parent_score = get_score(parent_node)\n",
    "\n",
    "        results.append({\n",
    "            \"node_id\": node_id,\n",
    "            \"plan_chain\": build_plan_chain_from_root(node_id),\n",
    "            \"cur_score\": cur_score,\n",
    "            \"parent_score\": parent_score,\n",
    "            \"score_diff\": cur_score - parent_score,\n",
    "            \"reward\": get_reward(node, parent_node),\n",
    "            \"maximize\": node.get(\"metric\", {}).get(\"maximize\"),\n",
    "        })\n",
    "\n",
    "    # -------- 5. group by parent & build pairs --------\n",
    "    parent2children = defaultdict(list)\n",
    "    for r in results:\n",
    "        parent_id = node2parent.get(r[\"node_id\"])\n",
    "        if parent_id is not None:\n",
    "            parent2children[parent_id].append(r)\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    for parent_id, children in parent2children.items():\n",
    "        if len(children) < 2:\n",
    "            continue\n",
    "\n",
    "        for a, b in combinations(children, 2):\n",
    "            if a[\"reward\"] == b[\"reward\"]:\n",
    "                continue\n",
    "\n",
    "            if a[\"reward\"] > b[\"reward\"]:\n",
    "                better, worse = a, b\n",
    "            else:\n",
    "                better, worse = b, a\n",
    "\n",
    "            pairs.append({\n",
    "                \"agent\":\"aide\",\n",
    "                \"comptation_name\": comp_name,\n",
    "                \"parent_id\": parent_id,\n",
    "                #\"better_node_id\": better[\"node_id\"],\n",
    "                #\"worse_node_id\": worse[\"node_id\"],\n",
    "                \"winner\": better[\"plan_chain\"],\n",
    "                \"loser\": worse[\"plan_chain\"],\n",
    "                \"score_diff\": better[\"reward\"] - worse[\"reward\"],\n",
    "            })\n",
    "\n",
    "    return pairs\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def build_pairs_from_run_group(\n",
    "    run_group_dir: str,\n",
    "    max_pairs_per_comp: int = 500,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    遍历 run-group 目录下所有比赛，汇总 preference pairs\n",
    "    对每个 competition 施加 pair 数量上限\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    comp2pairs = defaultdict(list)\n",
    "    missing = []\n",
    "\n",
    "    for name in os.listdir(run_group_dir):\n",
    "        comp_dir = os.path.join(run_group_dir, name)\n",
    "        if not os.path.isdir(comp_dir):\n",
    "            continue\n",
    "\n",
    "        journal_path = os.path.join(comp_dir, \"logs\", \"journal.json\")\n",
    "        if not os.path.isfile(journal_path):\n",
    "            missing.append(comp_dir)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            pairs = build_pairs_from_journal(journal_path)\n",
    "\n",
    "            # competition 名从目录中抽\n",
    "            comp_name = name.split(\"_\")[0]\n",
    "            comp2pairs[comp_name].extend(pairs)\n",
    "\n",
    "            print(f\"[OK] {name}: {len(pairs)} pairs\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {name}: {e}\")\n",
    "\n",
    "    # -------- apply per-competition cap --------\n",
    "    all_pairs = []\n",
    "\n",
    "    for comp, plist in comp2pairs.items():\n",
    "        original = len(plist)\n",
    "\n",
    "        if original > max_pairs_per_comp:\n",
    "            plist = random.sample(plist, max_pairs_per_comp)\n",
    "            print(f\"[CAP] {comp}: {original} -> {max_pairs_per_comp}\")\n",
    "\n",
    "        all_pairs.extend(plist)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total competitions processed: {len(comp2pairs)}\")\n",
    "    print(f\"Total preference pairs: {len(all_pairs)}\")\n",
    "    print(f\"Missing journal.json: {len(missing)}\")\n",
    "\n",
    "    return all_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808913ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(combined)\n",
    "\n",
    "# 需要限流的 competition\n",
    "CAP_COMPS = {\n",
    "    \"random-acts-of-pizza\": 2000,\n",
    "    \"text-normalization-challenge-russian-language\": 2000,\n",
    "    \"nomad2018-predict-transparent-conductors\":2000,\n",
    "    \"detecting-insults-in-social-commentary\":2000,\n",
    "    \"mlsp-2013-birds\":2000,\n",
    "    \"new-york-city-taxi-fare-prediction\":2000\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for comp, g in df.groupby(\"competition\"):\n",
    "    if comp in CAP_COMPS:\n",
    "        dfs.append(g.sample(n=CAP_COMPS[comp], random_state=42))\n",
    "    else:\n",
    "        dfs.append(g)\n",
    "\n",
    "df_capped = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 看一下新分布\n",
    "comp_counts_after = (\n",
    "    df_capped[\"competition\"]\n",
    "    .value_counts()\n",
    "    .rename(\"num_pairs\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"competition\"})\n",
    ")\n",
    "\n",
    "print(comp_counts_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deaf8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_capped = df_capped.to_dict(\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a75c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/data/userdata/v-lijingyuan/vail_data/valid.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined_capped, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(combined_capped)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85538007",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_capped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17580be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_capped[11]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
