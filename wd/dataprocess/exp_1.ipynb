{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a9638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case study \n",
    "# exp baseline artistic-toad  : powerful-crow type 2    6个比赛4个比基线高 curious-cattle type 1    6个比赛5个比基线高 \n",
    "import pandas as pd \n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"artistic-toad\"\n",
    "\n",
    "type_1 = \"humble-cardinal\"#\"powerful-crow\"\n",
    "\n",
    "type_2 = \"curious-cattle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = [\n",
    "    \"us-patent-phrase-to-phrase-matching\",\n",
    "    \"tweet-sentiment-extraction\",\n",
    "    \"jigsaw-toxic-comment-classification-challenge\", \"cassava-leaf-disease-classification\",\"leaf-classification\",\"whale-categorization-playground\",\n",
    "    \"h-and-m-personalized-fashion-recommendations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19bc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = [type_1,type_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = []\n",
    "\n",
    "for exp in EXP:\n",
    "    p0= f'/data/share_folder_local/amlt/{exp}/combined_logs/summary.pkl'\n",
    "    with open(p0, 'rb') as f:\n",
    "        summary  = pickle.load(f)\n",
    "    for idx, competition in enumerate(summary.keys()):\n",
    "        if competition.split(\".\")[-2] in EVO:\n",
    "            data = summary[competition]\n",
    "            print(f\"Experiment: {exp}, Competition: {competition}\")\n",
    "            test_scores_df = pd.DataFrame.from_dict(data[\"test_scores\"], orient=\"index\", columns=[\"Test Score\"])\n",
    "            test_scores_df.index.name = \"Loop\"\n",
    "            \n",
    "            # valid_scores_dict = data[\"valid_scores\"]\n",
    "            # # 提取 ensemble 验证分数\n",
    "            # ensemble_scores = {}\n",
    "            # for loop_id, df in valid_scores_dict.items():\n",
    "            #     if \"ensemble\" in df.index:\n",
    "            #         ensemble_scores[loop_id] = df.loc[\"ensemble\"].iloc[0]\n",
    "            ensemble_scores = test_scores_df[\"Test Score\"]\n",
    "            #print(ensemble_scores)\n",
    "            bronze_threshold = data[\"bronze_threshold\"]\n",
    "            silver_threshold = data[\"silver_threshold\"]\n",
    "            if ensemble_scores.size > 0:\n",
    "                if bronze_threshold > silver_threshold:\n",
    "                    F.append((exp, competition, ensemble_scores.min(), -1))\n",
    "                else:\n",
    "                    F.append((exp, competition, ensemble_scores.max(), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882591fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for comp, score_dict in comp2scores.items():\n",
    "    scores = list(score_dict.values())\n",
    "    if not scores:\n",
    "        continue\n",
    "    rows.append({\n",
    "        \"competition\": comp,\n",
    "        \"mean\": np.mean(scores),\n",
    "        \"std\": np.std(scores),\n",
    "        \"n\": len(scores),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"mean\", ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "data = F  # F 内部为 (exp, comp, score, direction)\n",
    "\n",
    "def strip_version(name):\n",
    "    if \".\" in name:\n",
    "        return name.rsplit(\".\", 1)[0]\n",
    "    return name\n",
    "\n",
    "# 第一步：按 competition + experiment 聚合所有 score\n",
    "comp2scores_raw = defaultdict(lambda: defaultdict(list))\n",
    "comp_direction = {}  # 每个 competition 的方向，只需要记录一次\n",
    "\n",
    "for exp, comp, score, direction in data:\n",
    "    comp_base = strip_version(comp)\n",
    "    comp2scores_raw[comp_base][exp].append(score)\n",
    "    comp_direction[comp_base] = direction\n",
    "\n",
    "# 第二步：求平均值\n",
    "comp2scores = defaultdict(dict)\n",
    "for comp, exp_dict in comp2scores_raw.items():\n",
    "    direction = comp_direction[comp]   # 1 or -1\n",
    "    for exp, score_list in exp_dict.items():\n",
    "        comp2scores[comp][exp] = (np.mean(score_list),np.std(score_list))\n",
    "        # if direction == 1:\n",
    "        #     comp2scores[comp][exp] = np.mean(score_list)\n",
    "        # else:\n",
    "        #     comp2scores[comp][exp] = np.mean(score_list)\n",
    "\n",
    "# target = \"curious-cattle\"\n",
    "\n",
    "# for comp, score_dict in comp2scores.items():\n",
    "\n",
    "#     if target not in score_dict:\n",
    "#         continue\n",
    "\n",
    "#     direction = comp_direction[comp]  #\n",
    "#     base = score_dict[target]\n",
    "\n",
    "    # diffs = {exp: (score - base) * direction for exp, score in score_dict.items()}\n",
    "\n",
    "    # sorted_exps = sorted(diffs, key=diffs.get, reverse=True)\n",
    "    # sorted_vals = [diffs[e] for e in sorted_exps]\n",
    "\n",
    "    # plt.figure(figsize=(5, 4))\n",
    "    # plt.barh(sorted_exps, sorted_vals)\n",
    "    # plt.axvline(0, color='black', linewidth=1)\n",
    "    # plt.title(f\"Difference from humble-cardinal — {comp}\")\n",
    "    # plt.xlabel(\"Performance Difference (positive = better)\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    # plt.savefig(f'diff_{comp}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for comp, exp_dict in comp2scores.items():\n",
    "    for exp, (mean, std) in exp_dict.items():\n",
    "        rows.append({\n",
    "            \"competition\": comp,\n",
    "            \"experiment\": exp,\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b50d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {\n",
    "    \"artistic-toad\": \"RD-Agent-GPT5\",\n",
    "    \"humble-cardinal\": \"RD-Agent-GPT5-world-model-type2\",\n",
    "    \"curious-cattle\": \"RD-Agent-GPT5-world-model-type1\",\n",
    "}\n",
    "df[\"experiment\"] = df[\"experiment\"].map(name_map)\n",
    "df.to_csv(\"competition_experiment_stats_renamed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b64ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_exp= [\"artistic-toad\"] +[\"humble-cardinal\"] +[\"curious-cattle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55878b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa62e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
