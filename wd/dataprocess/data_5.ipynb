{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbeab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = \"/data/userdata/v-lijingyuan/dpo/final_data_diff_1.json\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[:10])  # 如果是 list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c83574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_as_list(path):\n",
    "    data = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"[SKIP] line {idx}: {e}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae0734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "src_path = \"/data/userdata/v-lijingyuan/dpo/final_data_diff_1.json\"\n",
    "mapping_path = \"/data/userdata/v-lijingyuan/rl_pipe_line/final_teacher_chain_v4.jsonl\"\n",
    "#out_path = \"/data/userdata/v-lijingyuan/dpo/final_data_diff_2.json\"\n",
    "\n",
    "mapping_data =  load_jsonl_as_list(mapping_path)\n",
    "\n",
    "\n",
    "mapping = {}\n",
    "for obj in mapping_data:\n",
    "    key = (obj[\"comptation_name\"], obj[\"hypothesis_chain\"])\n",
    "    mapping[key] = obj[\"new_hypothesis_chain\"]\n",
    "\n",
    "print(f\"Loaded {len(mapping)} hypothesis mappings\")\n",
    "\n",
    "# ===== 2. 读取原始 DPO 数据 =====\n",
    "with open(src_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(data)} DPO samples\")\n",
    "\n",
    "# ===== 3. 批量替换 =====\n",
    "replaced_winner = 0\n",
    "replaced_loser = 0\n",
    "\n",
    "for idx, sample in enumerate(data):\n",
    "    comp = sample.get(\"comptation_name\")\n",
    "\n",
    "    # 打标识（可选）\n",
    "    sample[\"_replace_flag\"] = {\"winner\": False, \"loser\": False}\n",
    "\n",
    "    # winner\n",
    "    if \"winner\" in sample:\n",
    "        key = (comp, sample[\"winner\"])\n",
    "        if key in mapping:\n",
    "            print(f\"[MATCH][{idx}] WINNER | {comp}\")\n",
    "            sample[\"winner\"] = mapping[key]\n",
    "            sample[\"_replace_flag\"][\"winner\"] = True\n",
    "            replaced_winner += 1\n",
    "\n",
    "    # loser\n",
    "    if \"loser\" in sample:\n",
    "        key = (comp, sample[\"loser\"])\n",
    "        if key in mapping:\n",
    "            print(f\"[MATCH][{idx}] LOSER  | {comp}\")\n",
    "            sample[\"loser\"] = mapping[key]\n",
    "            sample[\"_replace_flag\"][\"loser\"] = True\n",
    "            replaced_loser += 1\n",
    "\n",
    "# # ===== 4. 写回 =====\n",
    "# with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Replaced winner: {replaced_winner}\")\n",
    "print(f\"Replaced loser : {replaced_loser}\")\n",
    "#print(f\"Saved to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# =========================\n",
    "# utils\n",
    "# =========================\n",
    "def load_jsonl_as_list(path: str) -> List[Dict]:\n",
    "    data = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"[WARN] skip bad line {i}: {e}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "# =========================\n",
    "# paths\n",
    "# =========================\n",
    "src_path = \"/data/userdata/v-lijingyuan/dpo/final_data_diff_1.json\"\n",
    "mapping_path = \"/data/userdata/v-lijingyuan/rl_pipe_line/final_teacher_chain_v4.jsonl\"\n",
    "out_path = \"/data/userdata/v-lijingyuan/dpo/final_data_diff_2.json\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1. load mapping (jsonl)\n",
    "# =========================\n",
    "mapping_data = load_jsonl_as_list(mapping_path)\n",
    "\n",
    "mapping = {}\n",
    "for obj in mapping_data:\n",
    "    key = (obj[\"comptation_name\"], obj[\"hypothesis_chain\"])\n",
    "    mapping[key] = obj[\"new_hypothesis_chain\"]\n",
    "\n",
    "print(f\"[INFO] Loaded {len(mapping)} hypothesis mappings\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. load original DPO data\n",
    "# =========================\n",
    "with open(src_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"[INFO] Loaded {len(data)} DPO samples\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. batch replace + collect examples\n",
    "# =========================\n",
    "replaced_winner = 0\n",
    "replaced_loser = 0\n",
    "\n",
    "examples = []\n",
    "MAX_EXAMPLES = 1000\n",
    "\n",
    "for idx, sample in enumerate(data):\n",
    "    comp = sample.get(\"comptation_name\")\n",
    "\n",
    "    # mark replace flag\n",
    "    sample[\"_replace_flag\"] = {\"winner\": False, \"loser\": False}\n",
    "\n",
    "    # -------- winner --------\n",
    "    if \"winner\" in sample:\n",
    "        key = (comp, sample[\"winner\"])\n",
    "        if key in mapping:\n",
    "            old = sample[\"winner\"]\n",
    "            new = mapping[key]\n",
    "\n",
    "            sample[\"winner\"] = new\n",
    "            sample[\"_replace_flag\"][\"winner\"] = True\n",
    "            replaced_winner += 1\n",
    "\n",
    "            if len(examples) < MAX_EXAMPLES:\n",
    "                examples.append({\n",
    "                    \"idx\": idx,\n",
    "                    \"type\": \"winner\",\n",
    "                    \"competition\": comp,\n",
    "                    \"old\": old,\n",
    "                    \"new\": new,\n",
    "                })\n",
    "\n",
    "    # -------- loser --------\n",
    "    if \"loser\" in sample:\n",
    "        key = (comp, sample[\"loser\"])\n",
    "        if key in mapping:\n",
    "            old = sample[\"loser\"]\n",
    "            new = mapping[key]\n",
    "\n",
    "            sample[\"loser\"] = new\n",
    "            sample[\"_replace_flag\"][\"loser\"] = True\n",
    "            replaced_loser += 1\n",
    "\n",
    "            if len(examples) < MAX_EXAMPLES:\n",
    "                examples.append({\n",
    "                    \"idx\": idx,\n",
    "                    \"type\": \"loser\",\n",
    "                    \"competition\": comp,\n",
    "                    \"old\": old,\n",
    "                    \"new\": new,\n",
    "                })\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. print replacement examples\n",
    "# =========================\n",
    "print(\"\\n========== REPLACEMENT EXAMPLES ==========\")\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    print(f\"\\n[EXAMPLE {i}] [{ex['type'].upper()}]\")\n",
    "    print(f\"idx        : {ex['idx']}\")\n",
    "    print(f\"competition: {ex['competition']}\")\n",
    "    print(\"OLD:\")\n",
    "    print(ex[\"old\"])\n",
    "    print(\"NEW:\")\n",
    "    print(ex[\"new\"])\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. stats\n",
    "# =========================\n",
    "print(\"\\n========== STATS ==========\")\n",
    "print(f\"Replaced winner: {replaced_winner}\")\n",
    "print(f\"Replaced loser : {replaced_loser}\")\n",
    "print(f\"Total samples  : {len(data)}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6. save result\n",
    "# ==================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69370aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51618cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "scp -r /data/userdata/v-lijingyuan/train_reward_stage3_3/last_run_7 \\\n",
    "      v-lijingyuan@ep12.213428.xyz:/home/v-lijingyuan/train_aira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da31688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# OLD TEXT（你给的内容，已示例性标红）\n",
    "# =========================\n",
    "old_text = [\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# NEW TEXT（占位，你自己填）\n",
    "# =========================\n",
    "new_text = (\n",
    "    \"Load a class-stratified random subset of the training data \"\n",
    "    \"(using a fixed random seed) for rapid experimentation and \"\n",
    "    \"memory-efficient local validation. \"\n",
    "    \"-> Introduce lightweight data-augmentation or synthetic resampling \"\n",
    "    \"strategies to mitigate class imbalance and enrich the learning \"\n",
    "    \"signal during early prototyping. \"\n",
    "    \"-> After validating modeling choices, fit a robust ensemble model \"\n",
    "    \"on the complete dataset, leveraging cross-validated early stopping \"\n",
    "    \"and class-balanced metrics to prevent overfitting and ensure fair \"\n",
    "    \"performance across all classes.\"\n",
    ")\n",
    "# 自动换行\n",
    "old_text = fill(old_text, width=100)\n",
    "new_text = fill(new_text, width=100)\n",
    "\n",
    "# =========================\n",
    "# 绘图\n",
    "# =========================\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "ax.text(\n",
    "    0.01, 0.95,\n",
    "    r\"\\textbf{Old Text (Overly Localized Feedback)}\" + \"\\n\\n\" + old_text,\n",
    "    va=\"top\",\n",
    "    ha=\"left\",\n",
    "    bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"#f2f2f2\", ec=\"black\")\n",
    ")\n",
    "\n",
    "ax.text(\n",
    "    0.01, 0.40,\n",
    "    r\"\\textbf{New Text (Improved Reasoning)}\" + \"\\n\\n\" + new_text,\n",
    "    va=\"top\",\n",
    "    ha=\"left\",\n",
    "    bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", ec=\"black\")\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(\"localized_feedback_old_new.pdf\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"localized_feedback_old_new.png\", dpi=300, bbox_inches=\"tight\")\n",
    "#plt.close()\n",
    "\n",
    "print(\"Saved: localized_feedback_old_new.pdf / localized_feedback_old_new.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4572aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from textwrap import fill\n",
    "\n",
    "# ===== 你自己填的内容 =====\n",
    "old_text = (\n",
    "\"Load a class-stratified random subset of 300,000 rows (random_state=42) from train.csv for training/validation to cut runtime/memory while preserving class distribution for trustworthy quick tests.->Add lightweight domain features and sanitize out-of-range values, then retrain the same LightGBM on the 300k stratified subset. Specifically: (1) Create sin_aspect = sin((Aspect % 360) * pi/180) and cos_aspect = cos((Aspect % 360) * pi/180) to capture circular geometry; (2) Create elev_minus_vdh = Elevation - Vertical_Distance_To_Hydrology; (3) Create abs_vdh = abs(Vertical_Distance_To_Hydrology); (4) Create hydrology_dist = sqrt(Horizontal_Distance_To_Hydrology^2 + Vertical_Distance_To_Hydrology^2); (5) Create road_fire_diff = Horizontal_Distance_To_Roadways - Horizontal_Distance_To_Fire_Points and road_fire_sum = Horizontal_Distance_To_Roadways + Horizontal_Distance_To_Fire_Points. Sanitize values consistently in train/test: clip all Horizontal_Distance_* features at >= 0, keep Vertical_Distance_To_Hydrology signed (do not clip), and clip Hillshade_9am/Noon/3pm into [0, 255]. Keep all other training settings unchanged.->Leverage the full dataset with GPU-accelerated boosting and align early stopping with Accuracy. Specifically, replace the current CPU LightGBM trained on a 300k subsample with XGBoost GPU trained on all 3.6M rows while keeping the existing sanitation and engineered features. Implement a minimal-count–aware 90/10 holdout: route all samples of any class with count <= 5 entirely to training, then perform a stratified 90/10 split on the remaining rows. Map labels 1–7 to 0–6 for training. Train XGBoost with tree_method=gpu_hist, predictor=gpu_predictor, objective=multi:softprob, num_class=7, eval_metric=merror, early_stopping_rounds=100, and sensible GPU-friendly params (e.g., max_depth=8, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0, n_estimators up to 3000, single_precision_histogram=1). Use the best_iteration to predict class labels on the full test set and map back to 1–7. This reduces sampling noise, exploits the available GPU, and optimizes directly for Accuracy while safeguarding rare classes in the split.\"\n",
    ")\n",
    "\n",
    "new_text = (\n",
    "    \"Load a class-stratified random subset of the training data \"\n",
    "    \"(using a fixed random seed) for rapid experimentation and \"\n",
    "    \"memory-efficient local validation. \"\n",
    "    \"-> Introduce lightweight data-augmentation or synthetic resampling \"\n",
    "    \"strategies to mitigate class imbalance and enrich the learning \"\n",
    "    \"signal during early prototyping. \"\n",
    "    \"-> After validating modeling choices, fit a robust ensemble model \"\n",
    "    \"on the complete dataset, leveraging cross-validated early stopping \"\n",
    "    \"and class-balanced metrics to prevent overfitting and ensure fair \"\n",
    "    \"performance across all classes.\"\n",
    ")\n",
    "# ===========================\n",
    "\n",
    "# 自动换行，避免超出边界\n",
    "old_text = fill(old_text, width=100)\n",
    "new_text = fill(new_text, width=100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Old text box\n",
    "ax.text(\n",
    "    0.02, 0.95,\n",
    "    \"Hypothesis \\n\\n\" + old_text,\n",
    "    fontsize=9,\n",
    "    va=\"top\",\n",
    "    ha=\"left\",\n",
    "    linespacing=1.4,\n",
    "    bbox=dict(\n",
    "        boxstyle=\"round,pad=0.6\",\n",
    "        fc=\"#eeeeee\",      # 浅灰，更柔和\n",
    "        ec=\"#444444\",      # 深灰边框\n",
    "        lw=1.0\n",
    "    )\n",
    ")\n",
    "\n",
    "# ===== New text box =====\n",
    "ax.text(\n",
    "    0.75, 0.95,\n",
    "    \"New Hypothesis chian \\n\\n\" + new_text,\n",
    "    fontsize=9,\n",
    "    va=\"top\",\n",
    "    ha=\"left\",\n",
    "    linespacing=1.4,\n",
    "    bbox=dict(\n",
    "        boxstyle=\"round,pad=0.6\",\n",
    "        fc=\"#ffffff\",      # 白底，突出“改进”\n",
    "        ec=\"#444444\",\n",
    "        lw=1.0\n",
    "    )\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(\"localized_feedback_example.png\", dpi=300, bbox_inches=\"tight\")\n",
    "#plt.savefig(\"localized_feedback_example.pdf\", bbox_inches=\"tight\")\n",
    "#plt.close()\n",
    "\n",
    "#print(\"Saved: localized_feedback_example.png / .pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f556b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_text_lines = [\n",
    "\n",
    "    [\n",
    "        (\"Load a class-stratified random subset of \", \"black\"),\n",
    "        (\"300,000\", \"red\"),\n",
    "        (\" rows (\", \"black\"),\n",
    "        (\"random_state=42\", \"red\"),\n",
    "        (\") from train.csv for training/validation to cut runtime/memory \"\n",
    "         \"while preserving class distribution for trustworthy quick tests.\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"→ Add lightweight domain features and sanitize out-of-range values, \"\n",
    "         \"then retrain the same LightGBM on the \", \"black\"),\n",
    "        (\"300k\", \"red\"),\n",
    "        (\" stratified subset. Specifically:\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(1) Create \", \"black\"),\n",
    "        (\"sin_aspect = sin((Aspect % 360) * pi/180)\", \"red\"),\n",
    "        (\" and \", \"black\"),\n",
    "        (\"cos_aspect = cos((Aspect % 360) * pi/180)\", \"red\"),\n",
    "        (\" to capture circular geometry;\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(2) Create \", \"black\"),\n",
    "        (\"elev_minus_vdh = Elevation - Vertical_Distance_To_Hydrology\", \"red\"),\n",
    "        (\";\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(3) Create \", \"black\"),\n",
    "        (\"abs_vdh = abs(Vertical_Distance_To_Hydrology)\", \"red\"),\n",
    "        (\";\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(4) Create \", \"black\"),\n",
    "        (\"hydrology_dist = sqrt(Horizontal_Distance_To_Hydrology^2 + \"\n",
    "         \"Vertical_Distance_To_Hydrology^2)\", \"red\"),\n",
    "        (\";\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(5) Create \", \"black\"),\n",
    "        (\"road_fire_diff = Horizontal_Distance_To_Roadways - \"\n",
    "         \"Horizontal_Distance_To_Fire_Points\", \"red\"),\n",
    "        (\" and \", \"black\"),\n",
    "        (\"road_fire_sum = Horizontal_Distance_To_Roadways + \"\n",
    "         \"Horizontal_Distance_To_Fire_Points\", \"red\"),\n",
    "        (\".\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"Sanitize values consistently in train/test: clip all \", \"black\"),\n",
    "        (\"Horizontal_Distance_* >= 0\", \"red\"),\n",
    "        (\", keep \", \"black\"),\n",
    "        (\"Vertical_Distance_To_Hydrology signed\", \"red\"),\n",
    "        (\" (do not clip), and clip \", \"black\"),\n",
    "        (\"Hillshade_9am/Noon/3pm into [0, 255]\", \"red\"),\n",
    "        (\". Keep all other training settings unchanged.\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"→ Leverage the full dataset with \", \"black\"),\n",
    "        (\"GPU-accelerated boosting\", \"red\"),\n",
    "        (\" and align early stopping with \", \"black\"),\n",
    "        (\"Accuracy\", \"red\"),\n",
    "        (\". Specifically, replace the current CPU LightGBM trained on a \", \"black\"),\n",
    "        (\"300k\", \"red\"),\n",
    "        (\" subsample with \", \"black\"),\n",
    "        (\"XGBoost GPU\", \"red\"),\n",
    "        (\" trained on all \", \"black\"),\n",
    "        (\"3.6M\", \"red\"),\n",
    "        (\" rows.\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"Train XGBoost with \", \"black\"),\n",
    "        (\"tree_method=gpu_hist\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"predictor=gpu_predictor\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"objective=multi:softprob\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"num_class=7\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"early_stopping_rounds=100\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"max_depth=8\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"learning_rate=0.05\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"subsample=0.8\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"colsample_bytree=0.8\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"n_estimators=3000\", \"red\"),\n",
    "        (\".\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"Use the best_iteration to predict class labels on the full test set \"\n",
    "         \"and map back to 1–7. This reduces sampling noise, exploits the available GPU, \"\n",
    "         \"and optimizes directly for Accuracy while safeguarding rare classes in the split.\", \"black\"),\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import TextArea, HPacker, VPacker, AnchoredOffsetbox\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "line_boxes = []\n",
    "\n",
    "for line in old_text_lines:\n",
    "    areas = [\n",
    "        TextArea(\n",
    "            txt,\n",
    "            textprops=dict(color=color, fontsize=9)\n",
    "        )\n",
    "        for txt, color in line\n",
    "    ]\n",
    "    line_boxes.append(\n",
    "        HPacker(children=areas, align=\"baseline\", pad=0, sep=2)\n",
    "    )\n",
    "\n",
    "vbox = VPacker(children=line_boxes, align=\"left\", pad=4, sep=6)\n",
    "\n",
    "anchored_box = AnchoredOffsetbox(\n",
    "    loc=\"upper left\",\n",
    "    child=vbox,\n",
    "    pad=0.4,\n",
    "    frameon=True,\n",
    "    bbox_to_anchor=(0.02, 0.95),\n",
    "    bbox_transform=ax.transAxes,\n",
    ")\n",
    "\n",
    "anchored_box.patch.set_boxstyle(\"round,pad=0.5\")\n",
    "anchored_box.patch.set_facecolor(\"#eeeeee\")\n",
    "anchored_box.patch.set_edgecolor(\"#2B2424\")\n",
    "\n",
    "ax.add_artist(anchored_box)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import TextArea, HPacker, VPacker, AnchoredOffsetbox, DrawingArea\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# =========================\n",
    "# 1. Old text（富文本，部分红色）\n",
    "# =========================\n",
    "\n",
    "old_text_lines = [\n",
    "\n",
    "    [\n",
    "        (\"Load a class-stratified random subset of \", \"black\"),\n",
    "        (\"300,000\", \"red\"),\n",
    "        (\" rows (\", \"black\"),\n",
    "        (\"random_state=42\", \"red\"),\n",
    "        (\") from train.csv for training/validation to cut runtime/memory \"\n",
    "         \"while preserving class distribution for trustworthy quick tests.\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"→ Add lightweight domain features and sanitize out-of-range values, \"\n",
    "         \"then retrain the same LightGBM on the \", \"black\"),\n",
    "        (\"300k\", \"red\"),\n",
    "        (\" stratified subset. Specifically:\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(1) Create \", \"black\"),\n",
    "        (\"sin_aspect = sin((Aspect % 360) * pi/180)\", \"red\"),\n",
    "        (\" and \", \"black\"),\n",
    "        (\"cos_aspect = cos((Aspect % 360) * pi/180)\", \"red\"),\n",
    "        (\" to capture circular geometry;\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(2) Create \", \"black\"),\n",
    "        (\"elev_minus_vdh = Elevation - Vertical_Distance_To_Hydrology\", \"red\"),\n",
    "        (\";\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(3) Create \", \"black\"),\n",
    "        (\"abs_vdh = abs(Vertical_Distance_To_Hydrology)\", \"red\"),\n",
    "        (\";\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(4) Create \", \"black\"),\n",
    "        (\"hydrology_dist = sqrt(Horizontal_Distance_To_Hydrology^2 + \"\n",
    "         \"Vertical_Distance_To_Hydrology^2)\", \"red\"),\n",
    "        (\";\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"(5) Create \", \"black\"),\n",
    "        (\"road_fire_diff = Horizontal_Distance_To_Roadways - \"\n",
    "         \"Horizontal_Distance_To_Fire_Points\", \"red\"),\n",
    "        (\" and \", \"black\"),\n",
    "        (\"road_fire_sum = Horizontal_Distance_To_Roadways + \"\n",
    "         \"Horizontal_Distance_To_Fire_Points\", \"red\"),\n",
    "        (\".\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"Sanitize values consistently in train/test: clip all \", \"black\"),\n",
    "        (\"Horizontal_Distance_* >= 0\", \"red\"),\n",
    "        (\", keep \", \"black\"),\n",
    "        (\"Vertical_Distance_To_Hydrology signed\", \"red\"),\n",
    "        (\" (do not clip), and clip \", \"black\"),\n",
    "        (\"Hillshade_9am/Noon/3pm into [0, 255]\", \"red\"),\n",
    "        (\". Keep all other training settings unchanged.\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"→ Leverage the full dataset with \", \"black\"),\n",
    "        (\"GPU-accelerated boosting\", \"red\"),\n",
    "        (\" and align early stopping with \", \"black\"),\n",
    "        (\"Accuracy\", \"red\"),\n",
    "        (\". Specifically, replace the current CPU LightGBM trained on a \", \"black\"),\n",
    "        (\"300k\", \"red\"),\n",
    "        (\" subsample with \", \"black\"),\n",
    "        (\"XGBoost GPU\", \"red\"),\n",
    "        (\" trained on all \", \"black\"),\n",
    "        (\"3.6M\", \"red\"),\n",
    "        (\" rows.\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"Train XGBoost with \", \"black\"),\n",
    "        (\"tree_method=gpu_hist\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"predictor=gpu_predictor\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"objective=multi:softprob\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"num_class=7\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"early_stopping_rounds=100\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"max_depth=8\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"learning_rate=0.05\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"subsample=0.8\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"colsample_bytree=0.8\", \"red\"),\n",
    "        (\", \", \"black\"),\n",
    "        (\"n_estimators=3000\", \"red\"),\n",
    "        (\".\", \"black\"),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        (\"Use the best_iteration to predict class labels on the full test set \"\n",
    "         \"and map back to 1–7. This reduces sampling noise, exploits the available GPU, \"\n",
    "         \"and optimizes directly for Accuracy while safeguarding rare classes in the split.\", \"black\"),\n",
    "    ],\n",
    "]\n",
    "\n",
    "old_line_boxes = []\n",
    "for line in old_text_lines:\n",
    "    areas = [\n",
    "        TextArea(txt, textprops=dict(color=color, fontsize=9))\n",
    "        for txt, color in line\n",
    "    ]\n",
    "    old_line_boxes.append(\n",
    "        HPacker(children=areas, align=\"baseline\", pad=0, sep=2)\n",
    "    )\n",
    "\n",
    "old_block = VPacker(\n",
    "    children=old_line_boxes,\n",
    "    align=\"left\",\n",
    "    pad=0,\n",
    "    sep=5,\n",
    ")\n",
    "\n",
    "old_title = TextArea(\n",
    "    \"Original hypothesis chain\\n\",\n",
    "    textprops=dict(fontsize=10, weight=\"bold\")\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2. New text（普通文本）\n",
    "# =========================\n",
    "\n",
    "new_text = (\n",
    "    \"Load a class-stratified random subset of the training data \"\n",
    "    \"(using a fixed random seed) for rapid experimentation and \"\n",
    "    \"memory-efficient local validation.\\n\\n\"\n",
    "    \"→ Introduce lightweight data-augmentation or synthetic resampling \"\n",
    "    \"strategies to mitigate class imbalance and enrich the learning \"\n",
    "    \"signal during early prototyping.\\n\\n\"\n",
    "    \"→ After validating modeling choices, fit a robust ensemble model \"\n",
    "    \"on the complete dataset, leveraging cross-validated early stopping \"\n",
    "    \"and class-balanced metrics to prevent overfitting and ensure fair \"\n",
    "    \"performance across all classes.\"\n",
    ")\n",
    "\n",
    "new_title = TextArea(\n",
    "    \"\\nFuzzified hypothesis chain\\n\",\n",
    "    textprops=dict(fontsize=10, weight=\"bold\")\n",
    ")\n",
    "\n",
    "new_block = TextArea(\n",
    "    new_text,\n",
    "    textprops=dict(fontsize=9)\n",
    ")\n",
    "\n",
    "divider = DrawingArea(1, 1, 0, 0)\n",
    "rect = Rectangle((0, 0.45), width=1100, height=0.7, color=\"black\", transform=divider.get_transform())\n",
    "divider.add_artist(rect)\n",
    "\n",
    "\n",
    "vbox = VPacker(\n",
    "    children=[\n",
    "        old_title,\n",
    "        old_block,\n",
    "        divider,       # 分界线放在 Old / New 中间\n",
    "        new_title,\n",
    "        new_block,\n",
    "    ],\n",
    "    align=\"left\",\n",
    "    pad=6,\n",
    "    sep=10,\n",
    ")\n",
    "\n",
    "anchored_box = AnchoredOffsetbox(\n",
    "    loc=\"upper left\",\n",
    "    child=vbox,\n",
    "    pad=0.4,\n",
    "    frameon=True,\n",
    "    bbox_to_anchor=(0.02, 0.95),\n",
    "    bbox_transform=ax.transAxes,\n",
    ")\n",
    "\n",
    "anchored_box.patch.set_boxstyle(\"round,pad=0.6\")\n",
    "anchored_box.patch.set_facecolor(\"#f0f0f0\")\n",
    "anchored_box.patch.set_edgecolor(\"#2B2424\")\n",
    "\n",
    "ax.add_artist(anchored_box)\n",
    "plt.savefig(\n",
    "    \"hypothesis_chain_comparison.png\",  # 文件名\n",
    "    dpi=300,                            # 高清\n",
    "    bbox_inches='tight',                # 自动裁剪空白\n",
    "    pad_inches=0.1,                     # 周围留一点边距\n",
    ")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
